{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing\n",
    "import pandas as pd\n",
    "# Compresed Sparse row\n",
    "from scipy.sparse import csr_matrix\n",
    "# Nearest neighbours\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing relevant data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"items_info.dat\" contains data field seperated by \"\\t\" but some of the fields also contain \"\\t\" within the text of the file. This causes errors when the file is read directly. The next cell is trying to sort that error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block creates a new .dat file that contains only the first 6 columns and the last column (the remaining columns are not necessary for the project). \n",
    "with open('book_crossing/book_crossing/items_info.dat', 'r', encoding='utf-8') as infile, \\\n",
    "     open('book_crossing/book_crossing/items_info_clean.dat', 'w', encoding='utf-8') as outfile:\n",
    "    for line in infile:\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) >= 6:\n",
    "            selected_parts = parts[:6] + [parts[-1]]  # First 6 fields + last field\n",
    "            outfile.write('\\t'.join(selected_parts) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('book_crossing/book_crossing/book_ratings.dat', delimiter = '\\t')\n",
    "history = pd.read_csv('book_crossing/book_crossing/book_history.dat', delimiter = '\\t') # Books and readers history.\n",
    "items = pd.read_csv('book_crossing/book_crossing/items_info_clean.dat', delimiter = '\\t', on_bad_lines='skip')  # list of books and Ids (Primary id key)\n",
    "users = pd.read_csv('book_crossing/book_crossing/users_info.dat', delimiter = '\\t') # list of users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of ratings dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of readers\n",
    "n_readers = ratings['user'].nunique()\n",
    "# Total number of books\n",
    "n_books = ratings['item'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book Average ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ratings = ratings.groupby('item')['rating'].mean()\n",
    "avg_ratings_dict = dict(zip(avg_ratings.index, round(avg_ratings, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_titles = dict(zip(items['Book_ID'], items['Book-Title']))\n",
    "inv_book_titles = dict(zip(items['Book-Title'], items['Book_ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.98% of the books accessed were rated.\n",
      "The user who accessed the most books is user 1614 with 2088 books accessed.\n",
      "The user who rated the most books is user 1003 with 1092 books rated.\n",
      "The most accessed book was Airframe, accessed 718 times.\n",
      "The most rated book was Impossible Vacation, rated 160 times.\n"
     ]
    }
   ],
   "source": [
    "# What percent of books accessed were rated\n",
    "percent_rated = len(ratings) / len(history) * 100\n",
    "print(f'{round(percent_rated, 2)}% of the books accessed were rated.')\n",
    "# What user accessed the most books\n",
    "user_access = history.groupby('user')['item'].count().sort_values(ascending=False)\n",
    "print(f'The user who accessed the most books is user {user_access.index[0]} with {user_access.max()} books accessed.')\n",
    "# What user rated the most books\n",
    "user_ratings = ratings.groupby('user')['item'].count().sort_values(ascending=False)\n",
    "print(f'The user who rated the most books is user {user_ratings.index[0]} with {user_ratings.max()} books rated.')\n",
    "# What was the most accessed books\n",
    "book_access = history.value_counts('item')\n",
    "print(f'The most accessed book was {book_titles[book_access.index[0]]}, accessed {book_access.max()} times.')\n",
    "# What was the most rated books?\n",
    "book_ratings = ratings.value_counts('item')\n",
    "print(f'The most rated book was {book_titles[book_ratings.index[0]]}, rated {book_ratings.max()} times.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Books with rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rated_books = items[items['Book_ID'].isin(list(ratings['item'].unique()))]\n",
    "book_titles = dict(zip(rated_books['Book_ID'], rated_books['Book-Title']))\n",
    "inv_book_titles = dict(zip(rated_books['Book-Title'], rated_books['Book_ID']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Sparse Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sparse_matrix(df, user_id_name, item_id_name, rating_column_name):\n",
    "#     \"\"\"\n",
    "#     This function helps to create a sparse matrix (a matrix largely populated by zeroes) from your ratings dataset.\n",
    "    \n",
    "#     Parameters:\n",
    "#     df: Pandas DataFrame\n",
    "#     user_id_name (str): Column name of the user ID.\n",
    "#     item_id_name (str): Column name of the item ID.\n",
    "#     rating_column_name (str): Column name of the ratings.\n",
    "    \n",
    "#     Returns:\n",
    "#     - matrix: the resulting sparse matrix\n",
    "#     - user_map: a dictionary mapping original user IDs to matrix row indices\n",
    "#     - item_map: a dictionary mapping original item IDs to matrix column indices\n",
    "#     - inv_user_map: inverse mapping from row indices back to original user IDs\n",
    "#     - inv_item_map: inverse mapping from column indices back to original item IDs\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Stores the number of unique users and items in the dataset.\n",
    "#     # This is used in determining the shape of the sparse matrix.\n",
    "#     n_users = df[user_id_name].nunique()\n",
    "#     n_items = df[item_id_name].nunique()\n",
    "\n",
    "#     # Creates a map of the user/item IDs to new sequential indices.\n",
    "#     user_map = dict(zip(df[user_id_name].unique(), list(range(n_users))))\n",
    "#     item_map = dict(zip(df[item_id_name].unique(), list(range(n_items))))\n",
    "\n",
    "#     # Creates the inverse map of user/item IDs for referencing purposes.\n",
    "#     inv_user_map = dict(zip(list(range(n_users)), df[user_id_name].unique()))\n",
    "#     inv_item_map = dict(zip(list(range(n_items)), df[item_id_name].unique()))\n",
    "\n",
    "#     # Applies the new IDs to create index lists.\n",
    "#     user_index = [user_map[i] for i in df[user_id_name]]\n",
    "#     item_index = [item_map[i] for i in df[item_id_name]]\n",
    "\n",
    "#     # Creates the sparse matrix using Compressed Sparse Row (csr) format.\n",
    "#     item_matrix = csr_matrix((df[rating_column_name], (item_index, user_index)), shape=(n_items, n_users))\n",
    "#     user_matrix = csr_matrix((df[rating_column_name], (user_index, item_index)), shape=(n_users, n_items))\n",
    "\n",
    "#     return item_matrix, user_matrix, user_map, item_map, inv_user_map, inv_item_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sparse_matrix(df, user_id_name, item_id_name, rating_column_name):\n",
    "    \"\"\"\n",
    "    Create a sparse user-item matrix from a dataframe.\n",
    "    Returns the item and user matrices, mapping dictionaries, and inverse mappings.\n",
    "    \"\"\"\n",
    "\n",
    "    # Factorize ensures a consistent mapping\n",
    "    df[user_id_name], user_idx = pd.factorize(df[user_id_name])\n",
    "    df[item_id_name], item_idx = pd.factorize(df[item_id_name])\n",
    "\n",
    "    user_map = dict(zip(user_idx, range(len(user_idx))))\n",
    "    item_map = dict(zip(item_idx, range(len(item_idx))))\n",
    "    inv_user_map = dict(enumerate(user_idx))\n",
    "    inv_item_map = dict(enumerate(item_idx))\n",
    "\n",
    "    user_index = df[user_id_name]\n",
    "    item_index = df[item_id_name]\n",
    "    ratings = df[rating_column_name].astype(float)\n",
    "\n",
    "    item_matrix = csr_matrix((ratings, (item_index, user_index)))\n",
    "    user_matrix = csr_matrix((ratings, (user_index, item_index)))\n",
    "\n",
    "    return item_matrix, user_matrix, user_map, item_map, inv_user_map, inv_item_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_matrix, user_matrix, user_map, item_map, inv_user_map, inv_item_map = sparse_matrix(ratings, 'user', 'item', 'rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User similarity function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_users_suggestions(user_item_list, user_rating_list, df, user_id, n_similar_users, metric='cosine'):\n",
    "    \"\"\"\n",
    "    Generates personalized book recommendations by identifying similar users using KNN.\n",
    "    \"\"\"\n",
    "    # Step 1: Create a synthetic new user ID (one greater than current max)\n",
    "    new_user_id = df[user_id].max() + 1\n",
    "    df = df.copy()\n",
    "\n",
    "    # Step 2: Convert book titles to internal book IDs\n",
    "    user_item_id = [inv_book_titles[i] for i in user_item_list]\n",
    "\n",
    "    # Step 3: Add the new user and their ratings to the DataFrame\n",
    "    for index, item_id in enumerate(user_item_id):\n",
    "        df.loc[len(df)] = {'user': new_user_id, 'item': item_id, 'rating': user_rating_list[index]}\n",
    "\n",
    "    # Step 4: Rebuild sparse matrix with new user included\n",
    "    item_matrix, user_matrix, user_map, item_map, inv_user_map, inv_item_map = sparse_matrix(\n",
    "        df, 'user', 'item', 'rating'\n",
    "    )\n",
    "\n",
    "    # Step 5: Get the matrix row index for the new user\n",
    "    new_user_matrix_index = user_matrix.shape[0] -1\n",
    "    user_vector = user_matrix[new_user_matrix_index]\n",
    "\n",
    "    # Step 6: Fit KNN and find neighbors\n",
    "    k = n_similar_users + 1  # +1 to include the new user in neighbors\n",
    "    KNN = NearestNeighbors(n_neighbors=k, algorithm='brute', metric=metric)\n",
    "    KNN.fit(user_matrix)\n",
    "    neighbours = KNN.kneighbors(user_vector, return_distance=False)\n",
    "\n",
    "    # Step 7: Map back to user IDs, skipping the new user itself\n",
    "    neighbouring_user_ids = [inv_user_map[n] for n in neighbours.flatten() if inv_user_map[n] != new_user_id]\n",
    "\n",
    "    # Step 8: Pick top-rated books from similar users\n",
    "    book_suggestions = []\n",
    "    for uid in neighbouring_user_ids:\n",
    "        user_books = df[df['user'] == uid]\n",
    "        if not user_books.empty:\n",
    "            best_book = user_books.sort_values(by='rating', ascending=False)['item'].head(1)\n",
    "            book_id = int(best_book.values[0])\n",
    "            book_suggestions.append(book_titles[book_id])\n",
    "\n",
    "    return sorted(book_suggestions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # User similarity function\n",
    "# def similar_users_suggestions(user_item_list, user_rating_list, df, user_id, n_similar_users, metric='cosine'):\n",
    "#     \"\"\"\n",
    "#     Generates personalized book recommendations by identifying similar users using KNN.\n",
    "#     \"\"\"\n",
    "#     # Step 1: Create a synthetic new user ID (one greater than current max)\n",
    "#     new_user_id = df[user_id].max() + 1\n",
    "#     df = df.copy()\n",
    "\n",
    "#     # Step 2: Convert book titles to internal book IDs\n",
    "#     user_item_id = [inv_book_titles[i] for i in user_item_list]\n",
    "\n",
    "#     # Step 3: Add the new user and their ratings to the DataFrame\n",
    "#     for index, item_id in enumerate(user_item_id):\n",
    "#         df.loc[len(df)] = {'user': new_user_id, 'item': item_id, 'rating': user_rating_list[index]}\n",
    "\n",
    "#     # Step 4: Rebuild sparse matrix with new user included\n",
    "#     item_matrix, user_matrix, user_map, item_map, inv_user_map, inv_item_map = sparse_matrix(\n",
    "#         df, 'user', 'item', 'rating'\n",
    "#     )\n",
    "\n",
    "#     # Step 5: Get the matrix row index for the new user\n",
    "#     new_user_matrix_index = user_matrix.shape[0] -1\n",
    "#     user_vector = user_matrix[new_user_matrix_index]\n",
    "\n",
    "#     # Step 6: Fit KNN and find neighbors\n",
    "#     k = n_similar_users + 1  # +1 to include the new user in neighbors\n",
    "#     KNN = NearestNeighbors(n_neighbors=k, algorithm='brute', metric=metric)\n",
    "#     KNN.fit(user_matrix)\n",
    "#     neighbours = KNN.kneighbors(user_vector, return_distance=False)\n",
    "\n",
    "#     # Step 7: Map back to user IDs, skipping the new user itself\n",
    "#     neighbouring_user_ids = [inv_user_map[n] for n in neighbours.flatten() if inv_user_map[n] != new_user_id]\n",
    "\n",
    "#     # Step 8: Pick top-rated books from similar users\n",
    "#     book_suggestions = []\n",
    "#     for uid in neighbouring_user_ids:\n",
    "#         user_books = df[df['user'] == uid]\n",
    "#         if not user_books.empty:\n",
    "#             best_book = user_books.sort_values(by='rating', ascending=False)['item'].head(1)\n",
    "#             book_id = int(best_book.values[0])\n",
    "#             book_suggestions.append(book_titles[book_id])\n",
    "\n",
    "#     return book_suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How to Get Your Child to Love Reading: For Ravenous and Reluctant Readers Alike',\n",
       " \"Left Behind: A Novel of the Earth's Last Days (Left Behind No. 1)\",\n",
       " \"The Children's Zoo\",\n",
       " 'Writing for Story']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_list = ['The Mists of Avalon', 'Love Always Remembers: A Book of Poems', 'Great Expectations (Dover Thrift Editions)']\n",
    "user_rating_list = [4, 6, 3]\n",
    "books = similar_users_suggestions(user_item_list, user_rating_list, ratings, 'user', 4)\n",
    "books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item similarity function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_books(book, df, k, metric='cosine'):\n",
    "    \"\"\"\n",
    "    Finds k books similar to the given book based on item-item collaborative filtering.\n",
    "\n",
    "    Args:\n",
    "        book (str): The title of the book for which to find similar books.\n",
    "        df (pd.DataFrame): Ratings DataFrame with columns ['user', 'item', 'rating'].\n",
    "        k (int): Number of similar books to return.\n",
    "        metric (str, optional): Distance metric for KNN. Default is 'cosine'.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of book titles similar to the input book.\n",
    "    \n",
    "    Notes:\n",
    "        - `book_titles` and `inv_book_titles` must be defined globally.\n",
    "    \"\"\"\n",
    "    # Convert book title to item ID\n",
    "    book_id = inv_book_titles[book]\n",
    "\n",
    "    # Build item-user matrix\n",
    "    item_matrix, user_matrix, user_map, item_map, inv_user_map, inv_item_map = sparse_matrix(\n",
    "        df, 'user', 'item', 'rating'\n",
    "    )\n",
    "\n",
    "    # Get matrix row index for the book\n",
    "    book_loc = item_map[book_id]\n",
    "    book_vector = item_matrix[book_loc]\n",
    "\n",
    "    # Fit KNN\n",
    "    knn = NearestNeighbors(n_neighbors=k + 1, algorithm='brute', metric=metric)\n",
    "    knn.fit(item_matrix)\n",
    "\n",
    "    # Find neighbors\n",
    "    neighbours = knn.kneighbors(book_vector.reshape(1, -1), return_distance=False).flatten()\n",
    "\n",
    "    # Skip the first neighbor (it will be the book itself)\n",
    "    similar_ids = [inv_item_map[idx] for idx in neighbours[1:]]\n",
    "\n",
    "    # Map item IDs back to book titles\n",
    "    return [book_titles[item_id] for item_id in similar_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Berlin Noir: March Violets/the Pale Criminal/a German Requiem/3 Novels in 1 Volume (Penguin Crime/Mystery)',\n",
       " 'The Great Train Robbery',\n",
       " 'Miss You Like Crazy',\n",
       " 'See No Evil (Loving Dangerously) (Harlequin Superromance, No 722)',\n",
       " 'Outer Banks']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books = similar_books('To Kill a Mockingbird', ratings, 5)\n",
    "books"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
