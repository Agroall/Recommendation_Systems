{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing\n",
    "import pandas as pd\n",
    "# Compresed Sparse row\n",
    "from scipy.sparse import csr_matrix\n",
    "# Nearest neighbours\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing relevant data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"items_info.dat\" contains data field seperated by \"\\t\" but some of the fields also contain \"\\t\" within the text of the file. This causes errors when the file is read directly. The next cell is trying to sort that error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block creates a new .dat file that contains only the first 6 columns and the last column (the remaining columns are not necessary for the project). \n",
    "with open('book_crossing/book_crossing/items_info.dat', 'r', encoding='utf-8') as infile, \\\n",
    "     open('book_crossing/book_crossing/items_info_clean.dat', 'w', encoding='utf-8') as outfile:\n",
    "    for line in infile:\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) >= 6:\n",
    "            selected_parts = parts[:6] + [parts[-1]]  # First 6 fields + last field\n",
    "            outfile.write('\\t'.join(selected_parts) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('book_crossing/book_crossing/book_ratings.dat', delimiter = '\\t')\n",
    "history = pd.read_csv('book_crossing/book_crossing/book_history.dat', delimiter = '\\t') # Books and readers history.\n",
    "items = pd.read_csv('book_crossing/book_crossing/items_info_clean.dat', delimiter = '\\t', on_bad_lines='skip')  # list of books and Ids (Primary id key)\n",
    "users = pd.read_csv('book_crossing/book_crossing/users_info.dat', delimiter = '\\t') # list of users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of ratings dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of readers\n",
    "n_readers = ratings['user'].nunique()\n",
    "# Total number of books\n",
    "n_books = ratings['item'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book Average ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ratings = ratings.groupby('item')['rating'].mean()\n",
    "avg_ratings_dict = dict(zip(avg_ratings.index, round(avg_ratings, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_titles = dict(zip(items['Book_ID'], items['Book-Title']))\n",
    "inv_book_titles = dict(zip(items['Book-Title'], items['Book_ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.98% of the books accessed were rated.\n",
      "The user who accessed the most books is user 1614 with 2088 books accessed.\n",
      "The user who rated the most books is user 1003 with 1092 books rated.\n",
      "The most accessed book was Airframe, accessed 718 times.\n",
      "The most rated book was Impossible Vacation, rated 160 times.\n"
     ]
    }
   ],
   "source": [
    "# What percent of books accessed were rated\n",
    "percent_rated = len(ratings) / len(history) * 100\n",
    "print(f'{round(percent_rated, 2)}% of the books accessed were rated.')\n",
    "# What user accessed the most books\n",
    "user_access = history.groupby('user')['item'].count().sort_values(ascending=False)\n",
    "print(f'The user who accessed the most books is user {user_access.index[0]} with {user_access.max()} books accessed.')\n",
    "# What user rated the most books\n",
    "user_ratings = ratings.groupby('user')['item'].count().sort_values(ascending=False)\n",
    "print(f'The user who rated the most books is user {user_ratings.index[0]} with {user_ratings.max()} books rated.')\n",
    "# What was the most accessed books\n",
    "book_access = history.value_counts('item')\n",
    "print(f'The most accessed book was {book_titles[book_access.index[0]]}, accessed {book_access.max()} times.')\n",
    "# What was the most rated books?\n",
    "book_ratings = ratings.value_counts('item')\n",
    "print(f'The most rated book was {book_titles[book_ratings.index[0]]}, rated {book_ratings.max()} times.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Books with rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rated_books = items[items['Book_ID'].isin(list(ratings['item'].unique()))]\n",
    "book_titles = dict(zip(rated_books['Book_ID'], rated_books['Book-Title']))\n",
    "inv_book_titles = dict(zip(rated_books['Book-Title'], rated_books['Book_ID']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Sparse Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def sparse_matrix(df, user_id_name, item_id_name, rating_column_name):\n",
    "    \"\"\"\n",
    "    This function helps to create a sparse matrix (a matrix largely populated by zeroes) from your ratings dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    df: Pandas DataFrame\n",
    "    user_id_name (str): Column name of the user ID.\n",
    "    item_id_name (str): Column name of the item ID.\n",
    "    rating_column_name (str): Column name of the ratings.\n",
    "    \n",
    "    Returns:\n",
    "    - matrix: the resulting sparse matrix\n",
    "    - user_map: a dictionary mapping original user IDs to matrix row indices\n",
    "    - item_map: a dictionary mapping original item IDs to matrix column indices\n",
    "    - inv_user_map: inverse mapping from row indices back to original user IDs\n",
    "    - inv_item_map: inverse mapping from column indices back to original item IDs\n",
    "    \"\"\"\n",
    "    \n",
    "    # Stores the number of unique users and items in the dataset.\n",
    "    # This is used in determining the shape of the sparse matrix.\n",
    "    n_users = df[user_id_name].nunique()\n",
    "    n_items = df[item_id_name].nunique()\n",
    "\n",
    "    # Creates a map of the user/item IDs to new sequential indices.\n",
    "    user_map = dict(zip(df[user_id_name].unique(), list(range(n_users))))\n",
    "    item_map = dict(zip(df[item_id_name].unique(), list(range(n_items))))\n",
    "\n",
    "    # Creates the inverse map of user/item IDs for referencing purposes.\n",
    "    inv_user_map = dict(zip(list(range(n_users)), df[user_id_name].unique()))\n",
    "    inv_item_map = dict(zip(list(range(n_items)), df[item_id_name].unique()))\n",
    "\n",
    "    # Applies the new IDs to create index lists.\n",
    "    user_index = [user_map[i] for i in df[user_id_name]]\n",
    "    item_index = [item_map[i] for i in df[item_id_name]]\n",
    "\n",
    "    # Creates the sparse matrix using Compressed Sparse Row (csr) format.\n",
    "    item_matrix = csr_matrix((df[rating_column_name], (item_index, user_index)), shape=(n_items, n_users))\n",
    "    user_matrix = csr_matrix((df[rating_column_name], (user_index, item_index)), shape=(n_users, n_items))\n",
    "\n",
    "    return item_matrix, user_matrix, user_map, item_map, inv_user_map, inv_item_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_matrix, user_matrix, user_map, item_map, inv_user_map, inv_item_map = sparse_matrix(ratings, 'user', 'item', 'rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User similarity function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_users_suggestions(user_item_list, user_rating_list, df, user_id, \n",
    "                              n_similar_users, metric='cosine'):\n",
    "    \"\"\"\n",
    "    Generates personalized book recommendations by identifying similar users using K-Nearest Neighbors (KNN).\n",
    "\n",
    "    This function creates a synthetic user based on their rated books and computes their similarity\n",
    "    to existing users in the dataset. It then recommends the top-rated book from each of the most similar users.\n",
    "\n",
    "    Args:\n",
    "        user_item_list (list of str): A list of book titles the new user has rated.\n",
    "        user_rating_list (list of float): A list of ratings corresponding to the `user_item_list`.\n",
    "        df (pd.DataFrame): The user-item ratings dataframe with columns ['user', 'item', 'rating'].\n",
    "        user_id (str): The name of the user ID column in `df`.\n",
    "        user_matrix (csr_matrix): The existing user-item sparse matrix.\n",
    "        n_similar_users (int): Number of similar users to retrieve.\n",
    "        metric (str, optional): Similarity metric to use for KNN. Defaults to 'cosine'.\n",
    "\n",
    "    Returns:\n",
    "        list of str: A list of top-rated book titles from each of the `n_similar_users` most similar users.\n",
    "\n",
    "    Notes:\n",
    "        - `book_titles` and `inv_book_titles` must be defined globally:\n",
    "            - `book_titles` maps book ID to title\n",
    "            - `inv_book_titles` maps title to book ID\n",
    "        - If a neighbor has no rated books, they are skipped.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Create a new user ID and copy dataframe to avoid mutation\n",
    "    user = df[user_id].max() + 1\n",
    "    df = df.copy()\n",
    "\n",
    "    # Step 2: Map book titles to book IDs\n",
    "    user_item_id = [inv_book_titles[i] for i in user_item_list]\n",
    "\n",
    "    # Step 3: Add the new user's ratings to the DataFrame\n",
    "    for index, item_id in enumerate(user_item_id):\n",
    "        new_row = {'user': user, 'item': item_id, 'rating': user_rating_list[index]}\n",
    "        df.loc[len(df)] = new_row\n",
    "\n",
    "    # Step 4: Create new sparse matrices from updated df\n",
    "    item_matrix, user_matrix, user_map, item_map, inv_user_map, inv_item_map = sparse_matrix(\n",
    "        df, 'user', 'item', 'rating'\n",
    "    )\n",
    "\n",
    "    # Step 5: Fit KNN to user matrix\n",
    "    k = n_similar_users + 1  # +1 to include the new user\n",
    "    user_loc = user_map[user]\n",
    "    user_vector = user_matrix[user_loc]\n",
    "\n",
    "    KNN = NearestNeighbors(n_neighbors=k, algorithm='brute', metric=metric)\n",
    "    KNN.fit(user_matrix)\n",
    "    neighbours = KNN.kneighbors(user_vector.reshape(1, -1), return_distance=False)\n",
    "\n",
    "    # Step 6: Get similar user IDs, skipping the first (which is the new user)\n",
    "    neighbouring_user_ids = [inv_user_map[n] for n in neighbours.flatten()[1:]]\n",
    "\n",
    "    # Step 7: Get top-rated books from each neighbour\n",
    "    book_suggestions = []\n",
    "    for uid in neighbouring_user_ids:\n",
    "        user_books = df[df['user'] == uid]\n",
    "        if not user_books.empty:\n",
    "            best_book = user_books.sort_values(by='rating', ascending=False)['item'].head(1)\n",
    "            book_id = int(best_book.values[0])\n",
    "            book_suggestions.append(book_titles[book_id])\n",
    "\n",
    "    return book_suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The Girls' Guide to Hunting and Fishing\",\n",
       " 'Ladder of Years',\n",
       " 'Who Were the Pharaohs?: A History of Their Names With a List of Cartouches',\n",
       " 'The Elric Saga PT. II',\n",
       " 'Herzsprung']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_list = ['To Kill a Mockingbird', 'Timeline', 'Airframe', 'The Mummies of Urumchi', 'Decision in Normandy']\n",
    "user_rating_list = [10, 4, 5, 9, 1]\n",
    "books = similar_users_suggestions(user_item_list, user_rating_list, ratings, 'user', 5)\n",
    "books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item similarity function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def similar_books(book, df, k, metric='cosine'):\n",
    "    \"\"\"\n",
    "    Finds k books similar to the given book based on item-item collaborative filtering.\n",
    "\n",
    "    Args:\n",
    "        book (str): The title of the book for which to find similar books.\n",
    "        df (pd.DataFrame): Ratings DataFrame with columns ['user', 'item', 'rating'].\n",
    "        k (int): Number of similar books to return.\n",
    "        metric (str, optional): Distance metric for KNN. Default is 'cosine'.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of book titles similar to the input book.\n",
    "    \n",
    "    Notes:\n",
    "        - `book_titles` and `inv_book_titles` must be defined globally.\n",
    "    \"\"\"\n",
    "    # Convert book title to item ID\n",
    "    book_id = inv_book_titles[book]\n",
    "\n",
    "    # Build item-user matrix\n",
    "    item_matrix, user_matrix, user_map, item_map, inv_user_map, inv_item_map = sparse_matrix(\n",
    "        df, 'user', 'item', 'rating'\n",
    "    )\n",
    "\n",
    "    # Get matrix row index for the book\n",
    "    book_loc = item_map[book_id]\n",
    "    book_vector = item_matrix[book_loc]\n",
    "\n",
    "    # Fit KNN\n",
    "    knn = NearestNeighbors(n_neighbors=k + 1, algorithm='brute', metric=metric)\n",
    "    knn.fit(item_matrix)\n",
    "\n",
    "    # Find neighbors\n",
    "    neighbours = knn.kneighbors(book_vector.reshape(1, -1), return_distance=False).flatten()\n",
    "\n",
    "    # Skip the first neighbor (it will be the book itself)\n",
    "    similar_ids = [inv_item_map[idx] for idx in neighbours[1:]]\n",
    "\n",
    "    # Map item IDs back to book titles\n",
    "    return [book_titles[item_id] for item_id in similar_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Berlin Noir: March Violets/the Pale Criminal/a German Requiem/3 Novels in 1 Volume (Penguin Crime/Mystery)',\n",
       " 'The Great Train Robbery',\n",
       " 'Miss You Like Crazy',\n",
       " 'See No Evil (Loving Dangerously) (Harlequin Superromance, No 722)',\n",
       " 'Outer Banks']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books = similar_books('To Kill a Mockingbird', ratings, 5)\n",
    "books"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
